{"input": ["/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/lang8_train.32k.src.seg", "/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/lang8_train.32k.trg.seg"], "output": "train", "record": "", "model": "transformer", "vocab": ["/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/src.vocab.32k.txt", "/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/trg.vocab.32k.txt"], "num_threads": 6, "batch_size": 4096, "max_length": 256, "length_multiplier": 1, "mantissa_bits": 2, "warmup_steps": 4000, "train_steps": 100000, "buffer_size": 10000, "constant_batch_size": false, "device_list": [0], "update_cycle": 1, "initializer": "uniform_unit_scaling", "initializer_gain": 1.0, "scale_l1": 0.0, "scale_l2": 0.0, "optimizer": "Adam", "adam_beta1": 0.9, "adam_beta2": 0.98, "adam_epsilon": 1e-09, "clip_grad_norm": 0.0, "learning_rate": 1.0, "learning_rate_decay": "linear_warmup_rsqrt_decay", "learning_rate_boundaries": [0], "learning_rate_values": [0.0], "keep_checkpoint_max": 20, "keep_top_checkpoint_max": 5, "eval_steps": 2000, "eval_secs": 0, "eval_batch_size": 32, "top_beams": 1, "beam_size": 4, "decode_alpha": 0.6, "decode_length": 50, "validation": "/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/lang8_valid.32k.src.seg", "references": ["/data/disk1/private/wangmuzi/data/THUMT/data/lang8_seg/lang8_valid.32k.trg.seg"], "save_checkpoint_secs": 0, "save_checkpoint_steps": 1000, "only_save_trainable": false, "pad": "<pad>", "bos": "<eos>", "eos": "<eos>", "unk": "<unk>", "append_eos": false, "hidden_size": 512, "filter_size": 2048, "num_heads": 8, "num_encoder_layers": 6, "num_decoder_layers": 6, "attention_dropout": 0.0, "residual_dropout": 0.1, "relu_dropout": 0.0, "label_smoothing": 0.1, "attention_key_channels": 0, "attention_value_channels": 0, "layer_preprocess": "none", "layer_postprocess": "layer_norm", "multiply_embedding_mode": "sqrt_depth", "shared_embedding_and_softmax_weights": false, "shared_source_target_embedding": false}